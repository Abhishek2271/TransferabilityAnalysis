[32m[0801 17:23:07 @logger.py:92][0m Argv: .\cifar-convnet.py --gpu 0
[32m[0801 17:23:07 @fs.py:101][0m [5m[31mWRN[0m Env var $TENSORPACK_DATASET not set, using C:\Users\mku\tensorpack_data for datasets.
[32m[0801 17:23:07 @cifar.py:30][0m Found cifar10 data in C:\Users\mku\tensorpack_data\cifar10_data.
[32m[0801 17:23:07 @cifar.py:30][0m Found cifar10 data in C:\Users\mku\tensorpack_data\cifar10_data.
[32m[0801 17:23:08 @input_source.py:221][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0801 17:23:08 @trainers.py:47][0m Building graph for a single training tower ...
[32m[0801 17:23:10 @registry.py:90][0m 'conv1.1': [?, 3, 30, 30] --> [?, 64, 30, 30]
[32m[0801 17:23:10 @registry.py:90][0m 'conv1.2': [?, 64, 30, 30] --> [?, 64, 30, 30]
[32m[0801 17:23:10 @registry.py:90][0m 'pool1': [?, 64, 30, 30] --> [?, 64, 15, 15]
[32m[0801 17:23:10 @registry.py:90][0m 'conv2.1': [?, 64, 15, 15] --> [?, 128, 15, 15]
[32m[0801 17:23:10 @registry.py:90][0m 'conv2.2': [?, 128, 15, 15] --> [?, 128, 15, 15]
[32m[0801 17:23:10 @registry.py:90][0m 'pool2': [?, 128, 15, 15] --> [?, 128, 8, 8]
[32m[0801 17:23:10 @registry.py:90][0m 'conv3.1': [?, 128, 8, 8] --> [?, 128, 6, 6]
[32m[0801 17:23:10 @registry.py:90][0m 'conv3.2': [?, 128, 6, 6] --> [?, 128, 4, 4]
[32m[0801 17:23:10 @registry.py:90][0m 'fc0': [?, 128, 4, 4] --> [?, 1536]
[32m[0801 17:23:10 @registry.py:90][0m 'fc1': [?, 1536] --> [?, 512]
[32m[0801 17:23:10 @registry.py:90][0m 'linear': [?, 512] --> [?, 10]
[32m[0801 17:23:10 @regularize.py:97][0m regularize_cost() found 2 variables to regularize.
[32m[0801 17:23:10 @regularize.py:21][0m The following tensors will be regularized: fc0/W:0, fc1/W:0
[32m[0801 17:23:11 @model_utils.py:67][0m [36mList of Trainable Variables: 
[0mname              shape               #elements
----------------  ----------------  -----------
conv1.1/W         [3, 3, 3, 64]            1728
conv1.1/bn/gamma  [64]                       64
conv1.1/bn/beta   [64]                       64
conv1.2/W         [3, 3, 64, 64]          36864
conv1.2/bn/gamma  [64]                       64
conv1.2/bn/beta   [64]                       64
conv2.1/W         [3, 3, 64, 128]         73728
conv2.1/bn/gamma  [128]                     128
conv2.1/bn/beta   [128]                     128
conv2.2/W         [3, 3, 128, 128]       147456
conv2.2/bn/gamma  [128]                     128
conv2.2/bn/beta   [128]                     128
conv3.1/W         [3, 3, 128, 128]       147456
conv3.1/bn/gamma  [128]                     128
conv3.1/bn/beta   [128]                     128
conv3.2/W         [3, 3, 128, 128]       147456
conv3.2/bn/gamma  [128]                     128
conv3.2/bn/beta   [128]                     128
fc0/W             [2048, 1536]          3145728
fc0/b             [1536]                   1536
fc1/W             [1536, 512]            786432
fc1/b             [512]                     512
linear/W          [512, 10]                5120
linear/b          [10]                       10[36m
Number of trainable variables: 24
Number of parameters (elements): 4495306
Storage space needed for all trainable variables: 17.15MB[0m
[32m[0801 17:23:11 @base.py:207][0m Setup callbacks graph ...
[32m[0801 17:23:11 @inference_runner.py:148][0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...
[32m[0801 17:23:11 @summary.py:47][0m [MovingAverageSummary] 3 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.
[32m[0801 17:23:11 @summary.py:94][0m Summarizing collection 'summaries' of size 15.
[32m[0801 17:23:11 @graph.py:99][0m Applying collection UPDATE_OPS of 12 ops.
[32m[0801 17:23:11 @base.py:228][0m Creating the session ...
[32m[0801 17:23:13 @base.py:234][0m Initializing the session ...
[32m[0801 17:23:13 @base.py:241][0m Graph Finalized.
[32m[0801 17:23:13 @concurrency.py:37][0m Starting EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" ...
[32m[0801 17:23:14 @inference_runner.py:95][0m [InferenceRunner] Will eval 79 iterations
[32m[0801 17:23:14 @base.py:273][0m Start Epoch 1 ...
[32m[0801 17:24:01 @base.py:283][0m Epoch 1 (global_step 390) finished, time:47.2 seconds.
[32m[0801 17:24:02 @saver.py:82][0m Model saved to train_log\cifar10\model-390.
[32m[0801 17:24:08 @monitor.py:476][0m QueueInput/queue_size: 0.5
[32m[0801 17:24:08 @monitor.py:476][0m accuracy: 0.57146
[32m[0801 17:24:08 @monitor.py:476][0m cross_entropy_loss: 1.2382
[32m[0801 17:24:08 @monitor.py:476][0m lr: 0.01
[32m[0801 17:24:08 @monitor.py:476][0m regularize_loss: 0.42162
[32m[0801 17:24:08 @monitor.py:476][0m validation_accuracy: 0.53224
[32m[0801 17:24:08 @monitor.py:476][0m validation_cost: 1.4287
[32m[0801 17:24:08 @group.py:44][0m Callbacks took 6.766 sec in total. InferenceRunner: 6.42 seconds
[32m[0801 17:24:08 @base.py:273][0m Start Epoch 2 ...
[32m[0801 17:24:50 @base.py:283][0m Epoch 2 (global_step 780) finished, time:41.5 seconds.
[32m[0801 17:24:50 @saver.py:82][0m Model saved to train_log\cifar10\model-780.
[32m[0801 17:24:55 @monitor.py:476][0m QueueInput/queue_size: 13.439
[32m[0801 17:24:55 @monitor.py:476][0m accuracy: 0.71137
[32m[0801 17:24:55 @monitor.py:476][0m cross_entropy_loss: 0.88368
[32m[0801 17:24:55 @monitor.py:476][0m lr: 0.01
[32m[0801 17:24:55 @monitor.py:476][0m regularize_loss: 0.17766
[32m[0801 17:24:55 @monitor.py:476][0m validation_accuracy: 0.66644
[32m[0801 17:24:55 @monitor.py:476][0m validation_cost: 1.0032
[32m[0801 17:24:55 @group.py:44][0m Callbacks took 5.951 sec in total. InferenceRunner: 5.72 seconds
[32m[0801 17:24:55 @base.py:273][0m Start Epoch 3 ...
[32m[0801 17:25:33 @base.py:283][0m Epoch 3 (global_step 1170) finished, time:37.5 seconds.
[32m[0801 17:25:33 @saver.py:82][0m Model saved to train_log\cifar10\model-1170.
[32m[0801 17:25:40 @monitor.py:476][0m QueueInput/queue_size: 47.675
[32m[0801 17:25:40 @monitor.py:476][0m accuracy: 0.76268
[32m[0801 17:25:40 @monitor.py:476][0m cross_entropy_loss: 0.73892
[32m[0801 17:25:40 @monitor.py:476][0m lr: 0.01
[32m[0801 17:25:40 @monitor.py:476][0m regularize_loss: 0.14363
[32m[0801 17:25:40 @monitor.py:476][0m validation_accuracy: 0.7589
[32m[0801 17:25:40 @monitor.py:476][0m validation_cost: 0.71883
[32m[0801 17:25:40 @group.py:44][0m Callbacks took 7.163 sec in total. InferenceRunner: 6.91 seconds
[32m[0801 17:25:40 @base.py:273][0m Start Epoch 4 ...
[32m[0801 17:27:12 @base.py:283][0m Epoch 4 (global_step 1560) finished, time:1 minute 32 seconds.
[32m[0801 17:27:13 @saver.py:82][0m Model saved to train_log\cifar10\model-1560.
[32m[0801 17:27:50 @monitor.py:476][0m QueueInput/queue_size: 6.9311e-35
[32m[0801 17:27:50 @monitor.py:476][0m accuracy: 0.77379
[32m[0801 17:27:50 @monitor.py:476][0m cross_entropy_loss: 0.68018
[32m[0801 17:27:50 @monitor.py:476][0m lr: 0.01
[32m[0801 17:27:50 @monitor.py:476][0m regularize_loss: 0.1461
[32m[0801 17:27:50 @monitor.py:476][0m validation_accuracy: 0.72894
[32m[0801 17:27:50 @monitor.py:476][0m validation_cost: 0.8203
[32m[0801 17:27:50 @group.py:44][0m Callbacks took 37.879 sec in total. InferenceRunner: 37 seconds
[32m[0801 17:27:50 @base.py:273][0m Start Epoch 5 ...
[32m[0801 17:30:23 @base.py:283][0m Epoch 5 (global_step 1950) finished, time:2 minutes 32 seconds.
[32m[0801 17:30:24 @saver.py:82][0m Model saved to train_log\cifar10\model-1950.
[32m[0801 17:31:00 @monitor.py:476][0m QueueInput/queue_size: 1.2743e-38
[32m[0801 17:31:00 @monitor.py:476][0m accuracy: 0.80126
[32m[0801 17:31:00 @monitor.py:476][0m cross_entropy_loss: 0.62173
[32m[0801 17:31:00 @monitor.py:476][0m lr: 0.01
[32m[0801 17:31:00 @monitor.py:476][0m regularize_loss: 0.15045
[32m[0801 17:31:00 @monitor.py:476][0m validation_accuracy: 0.78827
[32m[0801 17:31:00 @monitor.py:476][0m validation_cost: 0.65074
[32m[0801 17:31:00 @group.py:44][0m Callbacks took 36.875 sec in total. InferenceRunner: 36.1 seconds
[32m[0801 17:31:00 @base.py:273][0m Start Epoch 6 ...
[32m[0801 17:33:23 @base.py:283][0m Epoch 6 (global_step 2340) finished, time:2 minutes 23 seconds.
[32m[0801 17:33:28 @saver.py:82][0m Model saved to train_log\cifar10\model-2340.
