[32m[1001 15:55:43 @logger.py:92][0m Argv: run_exp.py
[32m[1001 15:55:43 @input_source.py:221][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[1001 15:55:43 @trainers.py:48][0m Building graph for a single training tower ...
[32m[1001 15:55:43 @registry.py:90][0m 'conv0': [?, 28, 28, 1] --> [?, 28, 28, 16]
[32m[1001 15:55:43 @registry.py:90][0m 'pool0': [?, 28, 28, 16] --> [?, 14, 14, 16]
[32m[1001 15:55:43 @registry.py:90][0m 'conv1': [?, 14, 14, 16] --> [?, 14, 14, 16]
[32m[1001 15:55:43 @registry.py:90][0m 'conv2': [?, 14, 14, 16] --> [?, 14, 14, 16]
[32m[1001 15:55:43 @registry.py:90][0m 'pool1': [?, 14, 14, 16] --> [?, 7, 7, 16]
[32m[1001 15:55:43 @registry.py:90][0m 'conv3': [?, 7, 7, 16] --> [?, 7, 7, 16]
[32m[1001 15:55:43 @registry.py:90][0m 'fc0': [?, 7, 7, 16] --> [?, 512]
[32m[1001 15:55:43 @registry.py:90][0m 'linear': [?, 512] --> [?, 10]
[32m[1001 15:55:43 @regularize.py:97][0m regularize_cost() found 1 variables to regularize.
[32m[1001 15:55:43 @regularize.py:21][0m The following tensors will be regularized: fc0/W:0
[32m[1001 15:55:43 @model_utils.py:67][0m [36mList of Trainable Variables: 
[0mname      shape             #elements
--------  --------------  -----------
conv0/W   [3, 3, 1, 16]           144
conv0/b   [16]                     16
conv1/W   [3, 3, 16, 16]         2304
conv1/b   [16]                     16
conv2/W   [3, 3, 16, 16]         2304
conv2/b   [16]                     16
conv3/W   [3, 3, 16, 16]         2304
conv3/b   [16]                     16
fc0/W     [784, 512]           401408
fc0/b     [512]                   512
linear/W  [512, 10]              5120
linear/b  [10]                     10[36m
Number of trainable variables: 12
Number of parameters (elements): 414170
Storage space needed for all trainable variables: 1.58MB[0m
[32m[1001 15:55:43 @base.py:207][0m Setup callbacks graph ...
[32m[1001 15:55:44 @inference_runner.py:148][0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...
[32m[1001 15:55:44 @collection.py:152][0m Size of these collections were changed in InferenceTower: (logits: 1->2)
[32m[1001 15:55:44 @summary.py:47][0m [MovingAverageSummary] 5 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.
[32m[1001 15:55:44 @summary.py:94][0m Summarizing collection 'summaries' of size 18.
[32m[1001 15:55:44 @base.py:228][0m Creating the session ...
[32m[1001 15:55:46 @base.py:234][0m Initializing the session ...
[32m[1001 15:55:46 @base.py:241][0m Graph Finalized.
[32m[1001 15:55:46 @concurrency.py:37][0m Starting EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" ...
[32m[1001 15:55:46 @inference_runner.py:95][0m [InferenceRunner] Will eval 100 iterations
[32m[1001 15:55:46 @base.py:273][0m Start Epoch 1 ...
[32m[1001 15:56:00 @base.py:283][0m Epoch 1 (global_step 469) finished, time:13.5 seconds.
[32m[1001 15:56:00 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-469.
[32m[1001 15:56:01 @saver.py:166][0m Model at global_step=469 with maximum val_accuracy=0.9828 saved.
[32m[1001 15:56:01 @saver.py:166][0m Model at global_step=469 with minimum val_cross_entropy_loss=0.047136 saved.
[32m[1001 15:56:01 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:56:01 @monitor.py:476][0m accuracy: 0.96687
[32m[1001 15:56:01 @monitor.py:476][0m cross_entropy_loss: 0.10471
[32m[1001 15:56:01 @monitor.py:476][0m param-summary/conv0/W-rms: 0.48679
[32m[1001 15:56:01 @monitor.py:476][0m param-summary/conv1/W-rms: 0.12369
[32m[1001 15:56:01 @monitor.py:476][0m param-summary/conv2/W-rms: 0.12247
[32m[1001 15:56:01 @monitor.py:476][0m param-summary/conv3/W-rms: 0.12114
[32m[1001 15:56:01 @monitor.py:476][0m param-summary/fc0/W-rms: 0.050465
[32m[1001 15:56:01 @monitor.py:476][0m param-summary/linear/W-rms: 0.067938
[32m[1001 15:56:01 @monitor.py:476][0m regularize_loss: 0.0050922
[32m[1001 15:56:01 @monitor.py:476][0m total_cost: 0.1098
[32m[1001 15:56:01 @monitor.py:476][0m train_error: 0.033131
[32m[1001 15:56:01 @monitor.py:476][0m val_accuracy: 0.9828
[32m[1001 15:56:01 @monitor.py:476][0m val_cross_entropy_loss: 0.047136
[32m[1001 15:56:01 @base.py:273][0m Start Epoch 2 ...
[32m[1001 15:56:13 @base.py:283][0m Epoch 2 (global_step 938) finished, time:11.9 seconds.
[32m[1001 15:56:13 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-938.
[32m[1001 15:56:14 @saver.py:166][0m Model at global_step=938 with maximum val_accuracy=0.9873 saved.
[32m[1001 15:56:14 @saver.py:166][0m Model at global_step=938 with minimum val_cross_entropy_loss=0.036624 saved.
[32m[1001 15:56:14 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:56:14 @monitor.py:476][0m accuracy: 0.98291
[32m[1001 15:56:14 @monitor.py:476][0m cross_entropy_loss: 0.059642
[32m[1001 15:56:14 @monitor.py:476][0m param-summary/conv0/W-rms: 0.48728
[32m[1001 15:56:14 @monitor.py:476][0m param-summary/conv1/W-rms: 0.1274
[32m[1001 15:56:14 @monitor.py:476][0m param-summary/conv2/W-rms: 0.12562
[32m[1001 15:56:14 @monitor.py:476][0m param-summary/conv3/W-rms: 0.12351
[32m[1001 15:56:14 @monitor.py:476][0m param-summary/fc0/W-rms: 0.052125
[32m[1001 15:56:14 @monitor.py:476][0m param-summary/linear/W-rms: 0.070669
[32m[1001 15:56:14 @monitor.py:476][0m regularize_loss: 0.0054397
[32m[1001 15:56:14 @monitor.py:476][0m total_cost: 0.065082
[32m[1001 15:56:14 @monitor.py:476][0m train_error: 0.017088
[32m[1001 15:56:14 @monitor.py:476][0m val_accuracy: 0.9873
[32m[1001 15:56:14 @monitor.py:476][0m val_cross_entropy_loss: 0.036624
[32m[1001 15:56:14 @base.py:273][0m Start Epoch 3 ...
[32m[1001 15:56:26 @base.py:283][0m Epoch 3 (global_step 1407) finished, time:11.9 seconds.
[32m[1001 15:56:26 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-1407.
[32m[1001 15:56:27 @saver.py:166][0m Model at global_step=1407 with maximum val_accuracy=0.9888 saved.
[32m[1001 15:56:27 @saver.py:166][0m Model at global_step=1407 with minimum val_cross_entropy_loss=0.031819 saved.
[32m[1001 15:56:27 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:56:27 @monitor.py:476][0m accuracy: 0.98389
[32m[1001 15:56:27 @monitor.py:476][0m cross_entropy_loss: 0.049022
[32m[1001 15:56:27 @monitor.py:476][0m param-summary/conv0/W-rms: 0.48716
[32m[1001 15:56:27 @monitor.py:476][0m param-summary/conv1/W-rms: 0.13002
[32m[1001 15:56:27 @monitor.py:476][0m param-summary/conv2/W-rms: 0.12814
[32m[1001 15:56:27 @monitor.py:476][0m param-summary/conv3/W-rms: 0.12537
[32m[1001 15:56:27 @monitor.py:476][0m param-summary/fc0/W-rms: 0.053693
[32m[1001 15:56:27 @monitor.py:476][0m param-summary/linear/W-rms: 0.07313
[32m[1001 15:56:27 @monitor.py:476][0m regularize_loss: 0.0057706
[32m[1001 15:56:27 @monitor.py:476][0m total_cost: 0.054793
[32m[1001 15:56:27 @monitor.py:476][0m train_error: 0.016109
[32m[1001 15:56:27 @monitor.py:476][0m val_accuracy: 0.9888
[32m[1001 15:56:27 @monitor.py:476][0m val_cross_entropy_loss: 0.031819
[32m[1001 15:56:27 @base.py:273][0m Start Epoch 4 ...
[32m[1001 15:56:39 @base.py:283][0m Epoch 4 (global_step 1876) finished, time:11.9 seconds.
[32m[1001 15:56:39 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-1876.
[32m[1001 15:56:40 @saver.py:166][0m Model at global_step=1876 with maximum val_accuracy=0.9888 saved.
[32m[1001 15:56:40 @saver.py:166][0m Model at global_step=1876 with minimum val_cross_entropy_loss=0.031389 saved.
[32m[1001 15:56:40 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:56:40 @monitor.py:476][0m accuracy: 0.98786
[32m[1001 15:56:40 @monitor.py:476][0m cross_entropy_loss: 0.034806
[32m[1001 15:56:40 @monitor.py:476][0m param-summary/conv0/W-rms: 0.48919
[32m[1001 15:56:40 @monitor.py:476][0m param-summary/conv1/W-rms: 0.13299
[32m[1001 15:56:40 @monitor.py:476][0m param-summary/conv2/W-rms: 0.1306
[32m[1001 15:56:40 @monitor.py:476][0m param-summary/conv3/W-rms: 0.12728
[32m[1001 15:56:40 @monitor.py:476][0m param-summary/fc0/W-rms: 0.055129
[32m[1001 15:56:40 @monitor.py:476][0m param-summary/linear/W-rms: 0.075915
[32m[1001 15:56:40 @monitor.py:476][0m regularize_loss: 0.0060886
[32m[1001 15:56:40 @monitor.py:476][0m total_cost: 0.040895
[32m[1001 15:56:40 @monitor.py:476][0m train_error: 0.012142
[32m[1001 15:56:40 @monitor.py:476][0m val_accuracy: 0.9888
[32m[1001 15:56:40 @monitor.py:476][0m val_cross_entropy_loss: 0.031389
[32m[1001 15:56:40 @base.py:273][0m Start Epoch 5 ...
[32m[1001 15:56:52 @base.py:283][0m Epoch 5 (global_step 2345) finished, time:11.9 seconds.
[32m[1001 15:56:52 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-2345.
[32m[1001 15:56:53 @saver.py:166][0m Model at global_step=2345 with maximum val_accuracy=0.9902 saved.
[32m[1001 15:56:53 @saver.py:166][0m Model at global_step=2345 with minimum val_cross_entropy_loss=0.02999 saved.
[32m[1001 15:56:53 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:56:53 @monitor.py:476][0m accuracy: 0.99101
[32m[1001 15:56:53 @monitor.py:476][0m cross_entropy_loss: 0.02772
[32m[1001 15:56:53 @monitor.py:476][0m param-summary/conv0/W-rms: 0.49084
[32m[1001 15:56:53 @monitor.py:476][0m param-summary/conv1/W-rms: 0.13527
[32m[1001 15:56:53 @monitor.py:476][0m param-summary/conv2/W-rms: 0.13296
[32m[1001 15:56:53 @monitor.py:476][0m param-summary/conv3/W-rms: 0.12911
[32m[1001 15:56:53 @monitor.py:476][0m param-summary/fc0/W-rms: 0.056385
[32m[1001 15:56:53 @monitor.py:476][0m param-summary/linear/W-rms: 0.078572
[32m[1001 15:56:53 @monitor.py:476][0m regularize_loss: 0.0063669
[32m[1001 15:56:53 @monitor.py:476][0m total_cost: 0.034087
[32m[1001 15:56:53 @monitor.py:476][0m train_error: 0.0089901
[32m[1001 15:56:53 @monitor.py:476][0m val_accuracy: 0.9902
[32m[1001 15:56:53 @monitor.py:476][0m val_cross_entropy_loss: 0.02999
[32m[1001 15:56:53 @base.py:273][0m Start Epoch 6 ...
[32m[1001 15:57:05 @base.py:283][0m Epoch 6 (global_step 2814) finished, time:11.9 seconds.
[32m[1001 15:57:05 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-2814.
[32m[1001 15:57:06 @saver.py:166][0m Model at global_step=2814 with maximum val_accuracy=0.9905 saved.
[32m[1001 15:57:06 @saver.py:166][0m Model at global_step=2814 with minimum val_cross_entropy_loss=0.027759 saved.
[32m[1001 15:57:06 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:57:06 @monitor.py:476][0m accuracy: 0.99287
[32m[1001 15:57:06 @monitor.py:476][0m cross_entropy_loss: 0.022463
[32m[1001 15:57:06 @monitor.py:476][0m param-summary/conv0/W-rms: 0.49209
[32m[1001 15:57:06 @monitor.py:476][0m param-summary/conv1/W-rms: 0.13739
[32m[1001 15:57:06 @monitor.py:476][0m param-summary/conv2/W-rms: 0.13548
[32m[1001 15:57:06 @monitor.py:476][0m param-summary/conv3/W-rms: 0.1311
[32m[1001 15:57:06 @monitor.py:476][0m param-summary/fc0/W-rms: 0.057811
[32m[1001 15:57:06 @monitor.py:476][0m param-summary/linear/W-rms: 0.081039
[32m[1001 15:57:06 @monitor.py:476][0m regularize_loss: 0.0066951
[32m[1001 15:57:06 @monitor.py:476][0m total_cost: 0.029158
[32m[1001 15:57:06 @monitor.py:476][0m train_error: 0.0071319
[32m[1001 15:57:06 @monitor.py:476][0m val_accuracy: 0.9905
[32m[1001 15:57:06 @monitor.py:476][0m val_cross_entropy_loss: 0.027759
[32m[1001 15:57:06 @base.py:273][0m Start Epoch 7 ...
[32m[1001 15:57:18 @base.py:283][0m Epoch 7 (global_step 3283) finished, time:11.9 seconds.
[32m[1001 15:57:18 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-3283.
[32m[1001 15:57:19 @saver.py:166][0m Model at global_step=3283 with maximum val_accuracy=0.9913 saved.
[32m[1001 15:57:19 @saver.py:166][0m Model at global_step=3283 with minimum val_cross_entropy_loss=0.025975 saved.
[32m[1001 15:57:19 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:57:19 @monitor.py:476][0m accuracy: 0.99102
[32m[1001 15:57:19 @monitor.py:476][0m cross_entropy_loss: 0.027704
[32m[1001 15:57:19 @monitor.py:476][0m param-summary/conv0/W-rms: 0.49269
[32m[1001 15:57:19 @monitor.py:476][0m param-summary/conv1/W-rms: 0.13995
[32m[1001 15:57:19 @monitor.py:476][0m param-summary/conv2/W-rms: 0.13766
[32m[1001 15:57:19 @monitor.py:476][0m param-summary/conv3/W-rms: 0.13277
[32m[1001 15:57:19 @monitor.py:476][0m param-summary/fc0/W-rms: 0.059205
[32m[1001 15:57:19 @monitor.py:476][0m param-summary/linear/W-rms: 0.083564
[32m[1001 15:57:19 @monitor.py:476][0m regularize_loss: 0.0070202
[32m[1001 15:57:19 @monitor.py:476][0m total_cost: 0.034725
[32m[1001 15:57:19 @monitor.py:476][0m train_error: 0.0089801
[32m[1001 15:57:19 @monitor.py:476][0m val_accuracy: 0.9913
[32m[1001 15:57:19 @monitor.py:476][0m val_cross_entropy_loss: 0.025975
[32m[1001 15:57:19 @base.py:273][0m Start Epoch 8 ...
[32m[1001 15:57:31 @base.py:283][0m Epoch 8 (global_step 3752) finished, time:11.9 seconds.
[32m[1001 15:57:31 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-3752.
[32m[1001 15:57:32 @saver.py:166][0m Model at global_step=3752 with maximum val_accuracy=0.9916 saved.
[32m[1001 15:57:32 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:57:32 @monitor.py:476][0m accuracy: 0.9942
[32m[1001 15:57:32 @monitor.py:476][0m cross_entropy_loss: 0.02118
[32m[1001 15:57:32 @monitor.py:476][0m param-summary/conv0/W-rms: 0.4942
[32m[1001 15:57:32 @monitor.py:476][0m param-summary/conv1/W-rms: 0.14182
[32m[1001 15:57:32 @monitor.py:476][0m param-summary/conv2/W-rms: 0.13948
[32m[1001 15:57:32 @monitor.py:476][0m param-summary/conv3/W-rms: 0.13453
[32m[1001 15:57:32 @monitor.py:476][0m param-summary/fc0/W-rms: 0.06018
[32m[1001 15:57:32 @monitor.py:476][0m param-summary/linear/W-rms: 0.086192
[32m[1001 15:57:32 @monitor.py:476][0m regularize_loss: 0.0072558
[32m[1001 15:57:32 @monitor.py:476][0m total_cost: 0.028436
[32m[1001 15:57:32 @monitor.py:476][0m train_error: 0.0057953
[32m[1001 15:57:32 @monitor.py:476][0m val_accuracy: 0.9916
[32m[1001 15:57:32 @monitor.py:476][0m val_cross_entropy_loss: 0.026269
[32m[1001 15:57:32 @base.py:273][0m Start Epoch 9 ...
[32m[1001 15:57:44 @base.py:283][0m Epoch 9 (global_step 4221) finished, time:12.1 seconds.
[32m[1001 15:57:44 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-4221.
[32m[1001 15:57:45 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:57:45 @monitor.py:476][0m accuracy: 0.99244
[32m[1001 15:57:45 @monitor.py:476][0m cross_entropy_loss: 0.024622
[32m[1001 15:57:45 @monitor.py:476][0m param-summary/conv0/W-rms: 0.49442
[32m[1001 15:57:45 @monitor.py:476][0m param-summary/conv1/W-rms: 0.14395
[32m[1001 15:57:45 @monitor.py:476][0m param-summary/conv2/W-rms: 0.14133
[32m[1001 15:57:45 @monitor.py:476][0m param-summary/conv3/W-rms: 0.13617
[32m[1001 15:57:45 @monitor.py:476][0m param-summary/fc0/W-rms: 0.061505
[32m[1001 15:57:45 @monitor.py:476][0m param-summary/linear/W-rms: 0.088769
[32m[1001 15:57:45 @monitor.py:476][0m regularize_loss: 0.007579
[32m[1001 15:57:45 @monitor.py:476][0m total_cost: 0.032201
[32m[1001 15:57:45 @monitor.py:476][0m train_error: 0.0075597
[32m[1001 15:57:45 @monitor.py:476][0m val_accuracy: 0.9891
[32m[1001 15:57:45 @monitor.py:476][0m val_cross_entropy_loss: 0.032204
[32m[1001 15:57:45 @base.py:273][0m Start Epoch 10 ...
[32m[1001 15:57:57 @base.py:283][0m Epoch 10 (global_step 4690) finished, time:12 seconds.
[32m[1001 15:57:57 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-4690.
[32m[1001 15:57:58 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:57:58 @monitor.py:476][0m accuracy: 0.99174
[32m[1001 15:57:58 @monitor.py:476][0m cross_entropy_loss: 0.023049
[32m[1001 15:57:58 @monitor.py:476][0m param-summary/conv0/W-rms: 0.494
[32m[1001 15:57:58 @monitor.py:476][0m param-summary/conv1/W-rms: 0.14575
[32m[1001 15:57:58 @monitor.py:476][0m param-summary/conv2/W-rms: 0.14329
[32m[1001 15:57:58 @monitor.py:476][0m param-summary/conv3/W-rms: 0.13781
[32m[1001 15:57:58 @monitor.py:476][0m param-summary/fc0/W-rms: 0.062556
[32m[1001 15:57:58 @monitor.py:476][0m param-summary/linear/W-rms: 0.091316
[32m[1001 15:57:58 @monitor.py:476][0m regularize_loss: 0.0078355
[32m[1001 15:57:58 @monitor.py:476][0m total_cost: 0.030885
[32m[1001 15:57:58 @monitor.py:476][0m train_error: 0.008261
[32m[1001 15:57:58 @monitor.py:476][0m val_accuracy: 0.9897
[32m[1001 15:57:59 @monitor.py:476][0m val_cross_entropy_loss: 0.032803
[32m[1001 15:57:59 @base.py:273][0m Start Epoch 11 ...
[32m[1001 15:58:10 @base.py:283][0m Epoch 11 (global_step 5159) finished, time:12 seconds.
[32m[1001 15:58:11 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-5159.
[32m[1001 15:58:12 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:58:12 @monitor.py:476][0m accuracy: 0.99118
[32m[1001 15:58:12 @monitor.py:476][0m cross_entropy_loss: 0.020363
[32m[1001 15:58:12 @monitor.py:476][0m param-summary/conv0/W-rms: 0.49406
[32m[1001 15:58:12 @monitor.py:476][0m param-summary/conv1/W-rms: 0.14795
[32m[1001 15:58:12 @monitor.py:476][0m param-summary/conv2/W-rms: 0.14533
[32m[1001 15:58:12 @monitor.py:476][0m param-summary/conv3/W-rms: 0.13909
[32m[1001 15:58:12 @monitor.py:476][0m param-summary/fc0/W-rms: 0.063694
[32m[1001 15:58:12 @monitor.py:476][0m param-summary/linear/W-rms: 0.093656
[32m[1001 15:58:12 @monitor.py:476][0m regularize_loss: 0.0081274
[32m[1001 15:58:12 @monitor.py:476][0m total_cost: 0.02849
[32m[1001 15:58:12 @monitor.py:476][0m train_error: 0.0088238
[32m[1001 15:58:12 @monitor.py:476][0m val_accuracy: 0.9908
[32m[1001 15:58:12 @monitor.py:476][0m val_cross_entropy_loss: 0.031293
[32m[1001 15:58:12 @base.py:273][0m Start Epoch 12 ...
[32m[1001 15:58:23 @base.py:283][0m Epoch 12 (global_step 5628) finished, time:11.9 seconds.
[32m[1001 15:58:24 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-5628.
[32m[1001 15:58:25 @saver.py:166][0m Model at global_step=5628 with maximum val_accuracy=0.9919 saved.
[32m[1001 15:58:25 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:58:25 @monitor.py:476][0m accuracy: 0.99377
[32m[1001 15:58:25 @monitor.py:476][0m cross_entropy_loss: 0.017796
[32m[1001 15:58:25 @monitor.py:476][0m param-summary/conv0/W-rms: 0.49338
[32m[1001 15:58:25 @monitor.py:476][0m param-summary/conv1/W-rms: 0.14947
[32m[1001 15:58:25 @monitor.py:476][0m param-summary/conv2/W-rms: 0.14727
[32m[1001 15:58:25 @monitor.py:476][0m param-summary/conv3/W-rms: 0.14076
[32m[1001 15:58:25 @monitor.py:476][0m param-summary/fc0/W-rms: 0.06464
[32m[1001 15:58:25 @monitor.py:476][0m param-summary/linear/W-rms: 0.096339
[32m[1001 15:58:25 @monitor.py:476][0m regularize_loss: 0.0083754
[32m[1001 15:58:25 @monitor.py:476][0m total_cost: 0.026171
[32m[1001 15:58:25 @monitor.py:476][0m train_error: 0.0062336
[32m[1001 15:58:25 @monitor.py:476][0m val_accuracy: 0.9919
[32m[1001 15:58:25 @monitor.py:476][0m val_cross_entropy_loss: 0.029354
[32m[1001 15:58:25 @base.py:273][0m Start Epoch 13 ...
[32m[1001 15:58:36 @base.py:283][0m Epoch 13 (global_step 6097) finished, time:12 seconds.
[32m[1001 15:58:37 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-6097.
[32m[1001 15:58:38 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:58:38 @monitor.py:476][0m accuracy: 0.99344
[32m[1001 15:58:38 @monitor.py:476][0m cross_entropy_loss: 0.017997
[32m[1001 15:58:38 @monitor.py:476][0m param-summary/conv0/W-rms: 0.49279
[32m[1001 15:58:38 @monitor.py:476][0m param-summary/conv1/W-rms: 0.15144
[32m[1001 15:58:38 @monitor.py:476][0m param-summary/conv2/W-rms: 0.14878
[32m[1001 15:58:38 @monitor.py:476][0m param-summary/conv3/W-rms: 0.14267
[32m[1001 15:58:38 @monitor.py:476][0m param-summary/fc0/W-rms: 0.065567
[32m[1001 15:58:38 @monitor.py:476][0m param-summary/linear/W-rms: 0.099029
[32m[1001 15:58:38 @monitor.py:476][0m regularize_loss: 0.0086117
[32m[1001 15:58:38 @monitor.py:476][0m total_cost: 0.026609
[32m[1001 15:58:38 @monitor.py:476][0m train_error: 0.0065577
[32m[1001 15:58:38 @monitor.py:476][0m val_accuracy: 0.9897
[32m[1001 15:58:38 @monitor.py:476][0m val_cross_entropy_loss: 0.035996
[32m[1001 15:58:38 @base.py:273][0m Start Epoch 14 ...
[32m[1001 15:58:49 @base.py:283][0m Epoch 14 (global_step 6566) finished, time:11.9 seconds.
[32m[1001 15:58:50 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-6566.
[32m[1001 15:58:50 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:58:50 @monitor.py:476][0m accuracy: 0.99339
[32m[1001 15:58:50 @monitor.py:476][0m cross_entropy_loss: 0.022143
[32m[1001 15:58:50 @monitor.py:476][0m param-summary/conv0/W-rms: 0.49261
[32m[1001 15:58:50 @monitor.py:476][0m param-summary/conv1/W-rms: 0.15318
[32m[1001 15:58:50 @monitor.py:476][0m param-summary/conv2/W-rms: 0.15048
[32m[1001 15:58:50 @monitor.py:476][0m param-summary/conv3/W-rms: 0.14408
[32m[1001 15:58:50 @monitor.py:476][0m param-summary/fc0/W-rms: 0.066512
[32m[1001 15:58:50 @monitor.py:476][0m param-summary/linear/W-rms: 0.10163
[32m[1001 15:58:50 @monitor.py:476][0m regularize_loss: 0.0088597
[32m[1001 15:58:50 @monitor.py:476][0m total_cost: 0.031003
[32m[1001 15:58:50 @monitor.py:476][0m train_error: 0.0066106
[32m[1001 15:58:50 @monitor.py:476][0m val_accuracy: 0.9906
[32m[1001 15:58:50 @monitor.py:476][0m val_cross_entropy_loss: 0.032297
[32m[1001 15:58:50 @base.py:273][0m Start Epoch 15 ...
[32m[1001 15:59:02 @base.py:283][0m Epoch 15 (global_step 7035) finished, time:11.9 seconds.
[32m[1001 15:59:02 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-7035.
[32m[1001 15:59:03 @saver.py:166][0m Model at global_step=7035 with maximum val_accuracy=0.9919 saved.
[32m[1001 15:59:03 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:59:03 @monitor.py:476][0m accuracy: 0.99451
[32m[1001 15:59:03 @monitor.py:476][0m cross_entropy_loss: 0.017856
[32m[1001 15:59:03 @monitor.py:476][0m param-summary/conv0/W-rms: 0.49089
[32m[1001 15:59:03 @monitor.py:476][0m param-summary/conv1/W-rms: 0.15513
[32m[1001 15:59:03 @monitor.py:476][0m param-summary/conv2/W-rms: 0.15224
[32m[1001 15:59:03 @monitor.py:476][0m param-summary/conv3/W-rms: 0.14543
[32m[1001 15:59:03 @monitor.py:476][0m param-summary/fc0/W-rms: 0.067406
[32m[1001 15:59:03 @monitor.py:476][0m param-summary/linear/W-rms: 0.10376
[32m[1001 15:59:03 @monitor.py:476][0m regularize_loss: 0.0090988
[32m[1001 15:59:03 @monitor.py:476][0m total_cost: 0.026955
[32m[1001 15:59:03 @monitor.py:476][0m train_error: 0.005488
[32m[1001 15:59:03 @monitor.py:476][0m val_accuracy: 0.9919
[32m[1001 15:59:03 @monitor.py:476][0m val_cross_entropy_loss: 0.031525
[32m[1001 15:59:03 @base.py:273][0m Start Epoch 16 ...
[32m[1001 15:59:15 @base.py:283][0m Epoch 16 (global_step 7504) finished, time:12 seconds.
[32m[1001 15:59:16 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-7504.
[32m[1001 15:59:16 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:59:16 @monitor.py:476][0m accuracy: 0.99441
[32m[1001 15:59:16 @monitor.py:476][0m cross_entropy_loss: 0.014253
[32m[1001 15:59:16 @monitor.py:476][0m param-summary/conv0/W-rms: 0.491
[32m[1001 15:59:16 @monitor.py:476][0m param-summary/conv1/W-rms: 0.15677
[32m[1001 15:59:16 @monitor.py:476][0m param-summary/conv2/W-rms: 0.15377
[32m[1001 15:59:16 @monitor.py:476][0m param-summary/conv3/W-rms: 0.14673
[32m[1001 15:59:16 @monitor.py:476][0m param-summary/fc0/W-rms: 0.067771
[32m[1001 15:59:16 @monitor.py:476][0m param-summary/linear/W-rms: 0.10596
[32m[1001 15:59:16 @monitor.py:476][0m regularize_loss: 0.0092007
[32m[1001 15:59:16 @monitor.py:476][0m total_cost: 0.023454
[32m[1001 15:59:16 @monitor.py:476][0m train_error: 0.0055897
[32m[1001 15:59:16 @monitor.py:476][0m val_accuracy: 0.9901
[32m[1001 15:59:16 @monitor.py:476][0m val_cross_entropy_loss: 0.032054
[32m[1001 15:59:16 @base.py:273][0m Start Epoch 17 ...
[32m[1001 15:59:28 @base.py:283][0m Epoch 17 (global_step 7973) finished, time:11.9 seconds.
[32m[1001 15:59:28 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-7973.
[32m[1001 15:59:29 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:59:29 @monitor.py:476][0m accuracy: 0.99627
[32m[1001 15:59:29 @monitor.py:476][0m cross_entropy_loss: 0.009005
[32m[1001 15:59:29 @monitor.py:476][0m param-summary/conv0/W-rms: 0.49185
[32m[1001 15:59:29 @monitor.py:476][0m param-summary/conv1/W-rms: 0.15881
[32m[1001 15:59:29 @monitor.py:476][0m param-summary/conv2/W-rms: 0.15548
[32m[1001 15:59:29 @monitor.py:476][0m param-summary/conv3/W-rms: 0.14843
[32m[1001 15:59:29 @monitor.py:476][0m param-summary/fc0/W-rms: 0.068478
[32m[1001 15:59:29 @monitor.py:476][0m param-summary/linear/W-rms: 0.10847
[32m[1001 15:59:29 @monitor.py:476][0m regularize_loss: 0.0094099
[32m[1001 15:59:29 @monitor.py:476][0m total_cost: 0.018415
[32m[1001 15:59:29 @monitor.py:476][0m train_error: 0.0037261
[32m[1001 15:59:29 @monitor.py:476][0m val_accuracy: 0.9918
[32m[1001 15:59:29 @monitor.py:476][0m val_cross_entropy_loss: 0.030749
[32m[1001 15:59:29 @base.py:273][0m Start Epoch 18 ...
[32m[1001 15:59:41 @base.py:283][0m Epoch 18 (global_step 8442) finished, time:11.9 seconds.
[32m[1001 15:59:41 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-8442.
[32m[1001 15:59:42 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:59:42 @monitor.py:476][0m accuracy: 0.99528
[32m[1001 15:59:42 @monitor.py:476][0m cross_entropy_loss: 0.011092
[32m[1001 15:59:42 @monitor.py:476][0m param-summary/conv0/W-rms: 0.49221
[32m[1001 15:59:42 @monitor.py:476][0m param-summary/conv1/W-rms: 0.16049
[32m[1001 15:59:42 @monitor.py:476][0m param-summary/conv2/W-rms: 0.15701
[32m[1001 15:59:42 @monitor.py:476][0m param-summary/conv3/W-rms: 0.1502
[32m[1001 15:59:42 @monitor.py:476][0m param-summary/fc0/W-rms: 0.069095
[32m[1001 15:59:42 @monitor.py:476][0m param-summary/linear/W-rms: 0.11076
[32m[1001 15:59:42 @monitor.py:476][0m regularize_loss: 0.0095756
[32m[1001 15:59:42 @monitor.py:476][0m total_cost: 0.020668
[32m[1001 15:59:42 @monitor.py:476][0m train_error: 0.0047248
[32m[1001 15:59:42 @monitor.py:476][0m val_accuracy: 0.9915
[32m[1001 15:59:42 @monitor.py:476][0m val_cross_entropy_loss: 0.029825
[32m[1001 15:59:42 @base.py:273][0m Start Epoch 19 ...
[32m[1001 15:59:54 @base.py:283][0m Epoch 19 (global_step 8911) finished, time:11.9 seconds.
[32m[1001 15:59:54 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-8911.
[32m[1001 15:59:55 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 15:59:55 @monitor.py:476][0m accuracy: 0.99557
[32m[1001 15:59:55 @monitor.py:476][0m cross_entropy_loss: 0.012471
[32m[1001 15:59:55 @monitor.py:476][0m param-summary/conv0/W-rms: 0.48993
[32m[1001 15:59:55 @monitor.py:476][0m param-summary/conv1/W-rms: 0.16196
[32m[1001 15:59:55 @monitor.py:476][0m param-summary/conv2/W-rms: 0.15841
[32m[1001 15:59:55 @monitor.py:476][0m param-summary/conv3/W-rms: 0.15128
[32m[1001 15:59:55 @monitor.py:476][0m param-summary/fc0/W-rms: 0.069961
[32m[1001 15:59:55 @monitor.py:476][0m param-summary/linear/W-rms: 0.11297
[32m[1001 15:59:55 @monitor.py:476][0m regularize_loss: 0.0098136
[32m[1001 15:59:55 @monitor.py:476][0m total_cost: 0.022285
[32m[1001 15:59:55 @monitor.py:476][0m train_error: 0.0044296
[32m[1001 15:59:55 @monitor.py:476][0m val_accuracy: 0.9915
[32m[1001 15:59:55 @monitor.py:476][0m val_cross_entropy_loss: 0.032325
[32m[1001 15:59:55 @base.py:273][0m Start Epoch 20 ...
[32m[1001 16:00:07 @base.py:283][0m Epoch 20 (global_step 9380) finished, time:11.9 seconds.
[32m[1001 16:00:07 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-9380.
[32m[1001 16:00:08 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 16:00:08 @monitor.py:476][0m accuracy: 0.99371
[32m[1001 16:00:08 @monitor.py:476][0m cross_entropy_loss: 0.015091
[32m[1001 16:00:08 @monitor.py:476][0m param-summary/conv0/W-rms: 0.49089
[32m[1001 16:00:08 @monitor.py:476][0m param-summary/conv1/W-rms: 0.16354
[32m[1001 16:00:08 @monitor.py:476][0m param-summary/conv2/W-rms: 0.15977
[32m[1001 16:00:08 @monitor.py:476][0m param-summary/conv3/W-rms: 0.15255
[32m[1001 16:00:08 @monitor.py:476][0m param-summary/fc0/W-rms: 0.070336
[32m[1001 16:00:08 @monitor.py:476][0m param-summary/linear/W-rms: 0.11524
[32m[1001 16:00:08 @monitor.py:476][0m regularize_loss: 0.0099179
[32m[1001 16:00:08 @monitor.py:476][0m total_cost: 0.025009
[32m[1001 16:00:08 @monitor.py:476][0m train_error: 0.0062917
[32m[1001 16:00:08 @monitor.py:476][0m val_accuracy: 0.9908
[32m[1001 16:00:08 @monitor.py:476][0m val_cross_entropy_loss: 0.036887
[32m[1001 16:00:08 @base.py:273][0m Start Epoch 21 ...
[32m[1001 16:00:20 @base.py:283][0m Epoch 21 (global_step 9849) finished, time:12.1 seconds.
[32m[1001 16:00:20 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-9849.
[32m[1001 16:00:21 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 16:00:21 @monitor.py:476][0m accuracy: 0.99534
[32m[1001 16:00:21 @monitor.py:476][0m cross_entropy_loss: 0.014933
[32m[1001 16:00:21 @monitor.py:476][0m param-summary/conv0/W-rms: 0.49042
[32m[1001 16:00:21 @monitor.py:476][0m param-summary/conv1/W-rms: 0.16529
[32m[1001 16:00:21 @monitor.py:476][0m param-summary/conv2/W-rms: 0.16152
[32m[1001 16:00:21 @monitor.py:476][0m param-summary/conv3/W-rms: 0.15408
[32m[1001 16:00:21 @monitor.py:476][0m param-summary/fc0/W-rms: 0.070939
[32m[1001 16:00:21 @monitor.py:476][0m param-summary/linear/W-rms: 0.11752
[32m[1001 16:00:21 @monitor.py:476][0m regularize_loss: 0.010091
[32m[1001 16:00:21 @monitor.py:476][0m total_cost: 0.025023
[32m[1001 16:00:21 @monitor.py:476][0m train_error: 0.0046557
[32m[1001 16:00:21 @monitor.py:476][0m val_accuracy: 0.9917
[32m[1001 16:00:21 @monitor.py:476][0m val_cross_entropy_loss: 0.032927
[32m[1001 16:00:21 @base.py:273][0m Start Epoch 22 ...
[32m[1001 16:00:34 @base.py:283][0m Epoch 22 (global_step 10318) finished, time:12.3 seconds.
[32m[1001 16:00:34 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-10318.
[32m[1001 16:00:35 @saver.py:166][0m Model at global_step=10318 with maximum val_accuracy=0.992 saved.
[32m[1001 16:00:35 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 16:00:35 @monitor.py:476][0m accuracy: 0.99693
[32m[1001 16:00:35 @monitor.py:476][0m cross_entropy_loss: 0.0096686
[32m[1001 16:00:35 @monitor.py:476][0m param-summary/conv0/W-rms: 0.49005
[32m[1001 16:00:35 @monitor.py:476][0m param-summary/conv1/W-rms: 0.16618
[32m[1001 16:00:35 @monitor.py:476][0m param-summary/conv2/W-rms: 0.1629
[32m[1001 16:00:35 @monitor.py:476][0m param-summary/conv3/W-rms: 0.15499
[32m[1001 16:00:35 @monitor.py:476][0m param-summary/fc0/W-rms: 0.070824
[32m[1001 16:00:35 @monitor.py:476][0m param-summary/linear/W-rms: 0.11948
[32m[1001 16:00:35 @monitor.py:476][0m regularize_loss: 0.01006
[32m[1001 16:00:35 @monitor.py:476][0m total_cost: 0.019729
[32m[1001 16:00:35 @monitor.py:476][0m train_error: 0.0030714
[32m[1001 16:00:35 @monitor.py:476][0m val_accuracy: 0.992
[32m[1001 16:00:35 @monitor.py:476][0m val_cross_entropy_loss: 0.03355
[32m[1001 16:00:35 @base.py:273][0m Start Epoch 23 ...
[32m[1001 16:00:47 @base.py:283][0m Epoch 23 (global_step 10787) finished, time:12 seconds.
[32m[1001 16:00:47 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-10787.
[32m[1001 16:00:48 @saver.py:166][0m Model at global_step=10787 with maximum val_accuracy=0.9927 saved.
[32m[1001 16:00:48 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 16:00:48 @monitor.py:476][0m accuracy: 0.99618
[32m[1001 16:00:48 @monitor.py:476][0m cross_entropy_loss: 0.010571
[32m[1001 16:00:48 @monitor.py:476][0m param-summary/conv0/W-rms: 0.48835
[32m[1001 16:00:48 @monitor.py:476][0m param-summary/conv1/W-rms: 0.16743
[32m[1001 16:00:48 @monitor.py:476][0m param-summary/conv2/W-rms: 0.16419
[32m[1001 16:00:48 @monitor.py:476][0m param-summary/conv3/W-rms: 0.15656
[32m[1001 16:00:48 @monitor.py:476][0m param-summary/fc0/W-rms: 0.071631
[32m[1001 16:00:48 @monitor.py:476][0m param-summary/linear/W-rms: 0.12143
[32m[1001 16:00:48 @monitor.py:476][0m regularize_loss: 0.010286
[32m[1001 16:00:48 @monitor.py:476][0m total_cost: 0.020857
[32m[1001 16:00:48 @monitor.py:476][0m train_error: 0.0038191
[32m[1001 16:00:48 @monitor.py:476][0m val_accuracy: 0.9927
[32m[1001 16:00:48 @monitor.py:476][0m val_cross_entropy_loss: 0.034462
[32m[1001 16:00:48 @base.py:273][0m Start Epoch 24 ...
[32m[1001 16:01:00 @base.py:283][0m Epoch 24 (global_step 11256) finished, time:12.1 seconds.
[32m[1001 16:01:00 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-11256.
[32m[1001 16:01:01 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 16:01:01 @monitor.py:476][0m accuracy: 0.99557
[32m[1001 16:01:01 @monitor.py:476][0m cross_entropy_loss: 0.010443
[32m[1001 16:01:01 @monitor.py:476][0m param-summary/conv0/W-rms: 0.488
[32m[1001 16:01:01 @monitor.py:476][0m param-summary/conv1/W-rms: 0.1692
[32m[1001 16:01:01 @monitor.py:476][0m param-summary/conv2/W-rms: 0.16588
[32m[1001 16:01:01 @monitor.py:476][0m param-summary/conv3/W-rms: 0.15774
[32m[1001 16:01:01 @monitor.py:476][0m param-summary/fc0/W-rms: 0.07181
[32m[1001 16:01:01 @monitor.py:476][0m param-summary/linear/W-rms: 0.12341
[32m[1001 16:01:01 @monitor.py:476][0m regularize_loss: 0.010339
[32m[1001 16:01:01 @monitor.py:476][0m total_cost: 0.020782
[32m[1001 16:01:01 @monitor.py:476][0m train_error: 0.0044318
[32m[1001 16:01:01 @monitor.py:476][0m val_accuracy: 0.9913
[32m[1001 16:01:01 @monitor.py:476][0m val_cross_entropy_loss: 0.03408
[32m[1001 16:01:01 @base.py:273][0m Start Epoch 25 ...
[32m[1001 16:01:13 @base.py:283][0m Epoch 25 (global_step 11725) finished, time:12 seconds.
[32m[1001 16:01:13 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-11725.
[32m[1001 16:01:14 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 16:01:14 @monitor.py:476][0m accuracy: 0.99668
[32m[1001 16:01:14 @monitor.py:476][0m cross_entropy_loss: 0.0084349
[32m[1001 16:01:14 @monitor.py:476][0m param-summary/conv0/W-rms: 0.48717
[32m[1001 16:01:14 @monitor.py:476][0m param-summary/conv1/W-rms: 0.17074
[32m[1001 16:01:14 @monitor.py:476][0m param-summary/conv2/W-rms: 0.16721
[32m[1001 16:01:14 @monitor.py:476][0m param-summary/conv3/W-rms: 0.15905
[32m[1001 16:01:14 @monitor.py:476][0m param-summary/fc0/W-rms: 0.071913
[32m[1001 16:01:14 @monitor.py:476][0m param-summary/linear/W-rms: 0.12543
[32m[1001 16:01:14 @monitor.py:476][0m regularize_loss: 0.010372
[32m[1001 16:01:14 @monitor.py:476][0m total_cost: 0.018807
[32m[1001 16:01:14 @monitor.py:476][0m train_error: 0.0033182
[32m[1001 16:01:14 @monitor.py:476][0m val_accuracy: 0.9921
[32m[1001 16:01:14 @monitor.py:476][0m val_cross_entropy_loss: 0.035632
[32m[1001 16:01:15 @base.py:273][0m Start Epoch 26 ...
[32m[1001 16:01:27 @base.py:283][0m Epoch 26 (global_step 12194) finished, time:12.1 seconds.
[32m[1001 16:01:27 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-12194.
[32m[1001 16:01:28 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 16:01:28 @monitor.py:476][0m accuracy: 0.99414
[32m[1001 16:01:28 @monitor.py:476][0m cross_entropy_loss: 0.02036
[32m[1001 16:01:28 @monitor.py:476][0m param-summary/conv0/W-rms: 0.4861
[32m[1001 16:01:28 @monitor.py:476][0m param-summary/conv1/W-rms: 0.17181
[32m[1001 16:01:28 @monitor.py:476][0m param-summary/conv2/W-rms: 0.16794
[32m[1001 16:01:28 @monitor.py:476][0m param-summary/conv3/W-rms: 0.16
[32m[1001 16:01:28 @monitor.py:476][0m param-summary/fc0/W-rms: 0.072321
[32m[1001 16:01:28 @monitor.py:476][0m param-summary/linear/W-rms: 0.12723
[32m[1001 16:01:28 @monitor.py:476][0m regularize_loss: 0.010482
[32m[1001 16:01:28 @monitor.py:476][0m total_cost: 0.030843
[32m[1001 16:01:28 @monitor.py:476][0m train_error: 0.0058649
[32m[1001 16:01:28 @monitor.py:476][0m val_accuracy: 0.991
[32m[1001 16:01:28 @monitor.py:476][0m val_cross_entropy_loss: 0.039708
[32m[1001 16:01:28 @base.py:273][0m Start Epoch 27 ...
[32m[1001 16:01:40 @base.py:283][0m Epoch 27 (global_step 12663) finished, time:12 seconds.
[32m[1001 16:01:40 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-12663.
[32m[1001 16:01:41 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 16:01:41 @monitor.py:476][0m accuracy: 0.9966
[32m[1001 16:01:41 @monitor.py:476][0m cross_entropy_loss: 0.013302
[32m[1001 16:01:41 @monitor.py:476][0m param-summary/conv0/W-rms: 0.48529
[32m[1001 16:01:41 @monitor.py:476][0m param-summary/conv1/W-rms: 0.17331
[32m[1001 16:01:41 @monitor.py:476][0m param-summary/conv2/W-rms: 0.16955
[32m[1001 16:01:41 @monitor.py:476][0m param-summary/conv3/W-rms: 0.16154
[32m[1001 16:01:41 @monitor.py:476][0m param-summary/fc0/W-rms: 0.072859
[32m[1001 16:01:41 @monitor.py:476][0m param-summary/linear/W-rms: 0.12947
[32m[1001 16:01:41 @monitor.py:476][0m regularize_loss: 0.01064
[32m[1001 16:01:41 @monitor.py:476][0m total_cost: 0.023941
[32m[1001 16:01:41 @monitor.py:476][0m train_error: 0.0034036
[32m[1001 16:01:41 @monitor.py:476][0m val_accuracy: 0.9915
[32m[1001 16:01:41 @monitor.py:476][0m val_cross_entropy_loss: 0.033873
[32m[1001 16:01:41 @base.py:273][0m Start Epoch 28 ...
[32m[1001 16:01:53 @base.py:283][0m Epoch 28 (global_step 13132) finished, time:12 seconds.
[32m[1001 16:01:53 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-13132.
[32m[1001 16:01:54 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 16:01:54 @monitor.py:476][0m accuracy: 0.99834
[32m[1001 16:01:54 @monitor.py:476][0m cross_entropy_loss: 0.004562
[32m[1001 16:01:54 @monitor.py:476][0m param-summary/conv0/W-rms: 0.48493
[32m[1001 16:01:54 @monitor.py:476][0m param-summary/conv1/W-rms: 0.17445
[32m[1001 16:01:54 @monitor.py:476][0m param-summary/conv2/W-rms: 0.17074
[32m[1001 16:01:54 @monitor.py:476][0m param-summary/conv3/W-rms: 0.16269
[32m[1001 16:01:54 @monitor.py:476][0m param-summary/fc0/W-rms: 0.072798
[32m[1001 16:01:54 @monitor.py:476][0m param-summary/linear/W-rms: 0.13148
[32m[1001 16:01:54 @monitor.py:476][0m regularize_loss: 0.01064
[32m[1001 16:01:54 @monitor.py:476][0m total_cost: 0.015202
[32m[1001 16:01:54 @monitor.py:476][0m train_error: 0.0016576
[32m[1001 16:01:54 @monitor.py:476][0m val_accuracy: 0.9918
[32m[1001 16:01:54 @monitor.py:476][0m val_cross_entropy_loss: 0.034601
[32m[1001 16:01:54 @base.py:273][0m Start Epoch 29 ...
[32m[1001 16:02:06 @base.py:283][0m Epoch 29 (global_step 13601) finished, time:12 seconds.
[32m[1001 16:02:06 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-13601.
[32m[1001 16:02:07 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 16:02:07 @monitor.py:476][0m accuracy: 0.99529
[32m[1001 16:02:07 @monitor.py:476][0m cross_entropy_loss: 0.012333
[32m[1001 16:02:07 @monitor.py:476][0m param-summary/conv0/W-rms: 0.48437
[32m[1001 16:02:07 @monitor.py:476][0m param-summary/conv1/W-rms: 0.17556
[32m[1001 16:02:07 @monitor.py:476][0m param-summary/conv2/W-rms: 0.17207
[32m[1001 16:02:07 @monitor.py:476][0m param-summary/conv3/W-rms: 0.16366
[32m[1001 16:02:07 @monitor.py:476][0m param-summary/fc0/W-rms: 0.072755
[32m[1001 16:02:07 @monitor.py:476][0m param-summary/linear/W-rms: 0.13317
[32m[1001 16:02:07 @monitor.py:476][0m regularize_loss: 0.010616
[32m[1001 16:02:07 @monitor.py:476][0m total_cost: 0.022949
[32m[1001 16:02:07 @monitor.py:476][0m train_error: 0.0047058
[32m[1001 16:02:07 @monitor.py:476][0m val_accuracy: 0.9917
[32m[1001 16:02:07 @monitor.py:476][0m val_cross_entropy_loss: 0.040292
[32m[1001 16:02:07 @base.py:273][0m Start Epoch 30 ...
[32m[1001 16:02:19 @base.py:283][0m Epoch 30 (global_step 14070) finished, time:12 seconds.
[32m[1001 16:02:19 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-14070.
[32m[1001 16:02:20 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 16:02:20 @monitor.py:476][0m accuracy: 0.99624
[32m[1001 16:02:20 @monitor.py:476][0m cross_entropy_loss: 0.012626
[32m[1001 16:02:20 @monitor.py:476][0m param-summary/conv0/W-rms: 0.48397
[32m[1001 16:02:20 @monitor.py:476][0m param-summary/conv1/W-rms: 0.17667
[32m[1001 16:02:20 @monitor.py:476][0m param-summary/conv2/W-rms: 0.17321
[32m[1001 16:02:20 @monitor.py:476][0m param-summary/conv3/W-rms: 0.16517
[32m[1001 16:02:20 @monitor.py:476][0m param-summary/fc0/W-rms: 0.072631
[32m[1001 16:02:20 @monitor.py:476][0m param-summary/linear/W-rms: 0.13458
[32m[1001 16:02:20 @monitor.py:476][0m regularize_loss: 0.010564
[32m[1001 16:02:20 @monitor.py:476][0m total_cost: 0.02319
[32m[1001 16:02:20 @monitor.py:476][0m train_error: 0.003765
[32m[1001 16:02:20 @monitor.py:476][0m val_accuracy: 0.991
[32m[1001 16:02:20 @monitor.py:476][0m val_cross_entropy_loss: 0.039442
[32m[1001 16:02:20 @base.py:273][0m Start Epoch 31 ...
[32m[1001 16:02:32 @base.py:283][0m Epoch 31 (global_step 14539) finished, time:11.9 seconds.
[32m[1001 16:02:32 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-14539.
[32m[1001 16:02:33 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 16:02:33 @monitor.py:476][0m accuracy: 0.9956
[32m[1001 16:02:33 @monitor.py:476][0m cross_entropy_loss: 0.013965
[32m[1001 16:02:33 @monitor.py:476][0m param-summary/conv0/W-rms: 0.48208
[32m[1001 16:02:33 @monitor.py:476][0m param-summary/conv1/W-rms: 0.17831
[32m[1001 16:02:33 @monitor.py:476][0m param-summary/conv2/W-rms: 0.17451
[32m[1001 16:02:33 @monitor.py:476][0m param-summary/conv3/W-rms: 0.16614
[32m[1001 16:02:33 @monitor.py:476][0m param-summary/fc0/W-rms: 0.072927
[32m[1001 16:02:33 @monitor.py:476][0m param-summary/linear/W-rms: 0.1365
[32m[1001 16:02:33 @monitor.py:476][0m regularize_loss: 0.010651
[32m[1001 16:02:33 @monitor.py:476][0m total_cost: 0.024616
[32m[1001 16:02:33 @monitor.py:476][0m train_error: 0.0043991
[32m[1001 16:02:33 @monitor.py:476][0m val_accuracy: 0.9904
[32m[1001 16:02:33 @monitor.py:476][0m val_cross_entropy_loss: 0.039271
[32m[1001 16:02:33 @base.py:273][0m Start Epoch 32 ...
[32m[1001 16:02:45 @base.py:283][0m Epoch 32 (global_step 15008) finished, time:11.9 seconds.
[32m[1001 16:02:45 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-15008.
[32m[1001 16:02:46 @saver.py:166][0m Model at global_step=15008 with maximum val_accuracy=0.993 saved.
[32m[1001 16:02:46 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 16:02:46 @monitor.py:476][0m accuracy: 0.99644
[32m[1001 16:02:46 @monitor.py:476][0m cross_entropy_loss: 0.0096936
[32m[1001 16:02:46 @monitor.py:476][0m param-summary/conv0/W-rms: 0.48086
[32m[1001 16:02:46 @monitor.py:476][0m param-summary/conv1/W-rms: 0.17977
[32m[1001 16:02:46 @monitor.py:476][0m param-summary/conv2/W-rms: 0.17555
[32m[1001 16:02:46 @monitor.py:476][0m param-summary/conv3/W-rms: 0.16751
[32m[1001 16:02:46 @monitor.py:476][0m param-summary/fc0/W-rms: 0.073049
[32m[1001 16:02:46 @monitor.py:476][0m param-summary/linear/W-rms: 0.13839
[32m[1001 16:02:46 @monitor.py:476][0m regularize_loss: 0.010698
[32m[1001 16:02:46 @monitor.py:476][0m total_cost: 0.020391
[32m[1001 16:02:46 @monitor.py:476][0m train_error: 0.0035575
[32m[1001 16:02:46 @monitor.py:476][0m val_accuracy: 0.993
[32m[1001 16:02:46 @monitor.py:476][0m val_cross_entropy_loss: 0.038727
[32m[1001 16:02:46 @base.py:273][0m Start Epoch 33 ...
[32m[1001 16:02:59 @base.py:283][0m Epoch 33 (global_step 15477) finished, time:12.1 seconds.
[32m[1001 16:02:59 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-15477.
[32m[1001 16:03:00 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 16:03:00 @monitor.py:476][0m accuracy: 0.99797
[32m[1001 16:03:00 @monitor.py:476][0m cross_entropy_loss: 0.0067341
[32m[1001 16:03:00 @monitor.py:476][0m param-summary/conv0/W-rms: 0.48021
[32m[1001 16:03:00 @monitor.py:476][0m param-summary/conv1/W-rms: 0.18066
[32m[1001 16:03:00 @monitor.py:476][0m param-summary/conv2/W-rms: 0.1769
[32m[1001 16:03:00 @monitor.py:476][0m param-summary/conv3/W-rms: 0.16858
[32m[1001 16:03:00 @monitor.py:476][0m param-summary/fc0/W-rms: 0.073035
[32m[1001 16:03:00 @monitor.py:476][0m param-summary/linear/W-rms: 0.1401
[32m[1001 16:03:00 @monitor.py:476][0m regularize_loss: 0.010701
[32m[1001 16:03:00 @monitor.py:476][0m total_cost: 0.017435
[32m[1001 16:03:00 @monitor.py:476][0m train_error: 0.0020333
[32m[1001 16:03:00 @monitor.py:476][0m val_accuracy: 0.9906
[32m[1001 16:03:00 @monitor.py:476][0m val_cross_entropy_loss: 0.047152
[32m[1001 16:03:00 @base.py:273][0m Start Epoch 34 ...
[32m[1001 16:03:12 @base.py:283][0m Epoch 34 (global_step 15946) finished, time:12.1 seconds.
[32m[1001 16:03:12 @saver.py:82][0m Model saved to logs\train_log\mnist-FP\model-15946.
[32m[1001 16:03:13 @monitor.py:476][0m QueueInput/queue_size: 50
[32m[1001 16:03:13 @monitor.py:476][0m accuracy: 0.99869
[32m[1001 16:03:13 @monitor.py:476][0m cross_entropy_loss: 0.0039596
[32m[1001 16:03:13 @monitor.py:476][0m param-summary/conv0/W-rms: 0.47959
[32m[1001 16:03:13 @monitor.py:476][0m param-summary/conv1/W-rms: 0.18138
[32m[1001 16:03:13 @monitor.py:476][0m param-summary/conv2/W-rms: 0.17799
[32m[1001 16:03:13 @monitor.py:476][0m param-summary/conv3/W-rms: 0.16963
[32m[1001 16:03:13 @monitor.py:476][0m param-summary/fc0/W-rms: 0.073033
[32m[1001 16:03:13 @monitor.py:476][0m param-summary/linear/W-rms: 0.14199
[32m[1001 16:03:13 @monitor.py:476][0m regularize_loss: 0.010709
[32m[1001 16:03:13 @monitor.py:476][0m total_cost: 0.014669
[32m[1001 16:03:13 @monitor.py:476][0m train_error: 0.0013116
[32m[1001 16:03:13 @monitor.py:476][0m val_accuracy: 0.9919
[32m[1001 16:03:13 @monitor.py:476][0m val_cross_entropy_loss: 0.039041
[32m[1001 16:03:13 @base.py:273][0m Start Epoch 35 ...
[32m[1001 16:03:16 @base.py:291][0m Detected Ctrl-C and exiting main loop.
[32m[1001 16:03:16 @input_source.py:177][0m [EnqueueThread] Thread EnqueueThread: enqueue dataflow to TF queue "QueueInput/input_queue" Exited.
